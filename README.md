# MITFutureMakers

## Responses:

### Day 1:
- In this joint program between MIT and SureStart, I am hoping to advance my knowledge in Deep Learning, Machine Learning, as well as other applications of Data Science. At the beginning of the program, we cover the fundamentals of python programming for Machine Learning with all necessary packages, including pandas, NumPy, and scikit-learn. For the rest of the program, we are going to build a Deep Learning project in a team of other students. 

### Day 2:
- On the second day of our program, we had a seminar on leadership & storytelling held by a Director of MIT Media Lab, Dr. Kong. In this session, we covered the importance of storytelling and self-recognition. As a result, this session has taught me not only a better storytelling strategy, but also gave me a sense that we all had our struggles in life and all deserve respect for staying strong and not giving up.

### Day 3:
- On day 3 we had an opportunity to learn about some concepts and models of machine learning and applications of scikit-learn. We learned about the bone structure of Artificial Intelligence and its sub-categories, such as Machine Learning, Neural Networks, and Deep Learning. There are two main components of Machine Learning that produce final predictions - a dataset (this includes data wrangling with raw data) with which we will feed the model and an algorithm (this includes data splitting, training, and validating models) which will compute prediction.

### Day 4:
 - For day 4, our task was to find a dataset that could solve a real-world problem. The problem that I was interested in was understanding the user-base in businesses such as Spotify and finding out how to maximize the efficiency of their software to propose possible improvements. Questions such as do people cluster certain artists on one playlist, does having more playlist followers increase or reduce the average listen time, and what variables lead to the longest listening time can be answered while exploring the dataset. The dataset can be found here https://www.kaggle.com/yamaerenay/spotify-dataset-19212020-160k-tracks

### Day 5 and 6:
- The Weekend

### Day 7:
- This day, we have learned about tensors and their value in machine learning. Mathematically speaking, Tensors are data containers, ranging from scalar to 3D matrixes, so a tensor is a container that can house data in N dimensions.  Tensors can be thought of as objects in an object-oriented sense, rather than just as data structures, from a computer science perspective. As for machine learning, tensors is a term and a set of techniques used in machine learning to describe the training and operation of deep learning models.

### Day 8:
- On this day we got to practice simple neural network models. The task was to detect sarcasm in the news dataset.

### Day 9:
- For day 9 our task was to extend the dataset for a CNN model to notice differences.

### Day 10:
- After playing "Survival of the Best Fit" game on ethical problems with AI and hiring, I have learned on how algorithmic basic occurs and possible ways to prevent it. The game itself was designed well, with implementation of both software engineering and machine learning (AI). After each step of completing the game, there was a series of questions to answer, and the game would proceed with the option that we choose and then adapt to our results. A real-world example that seems to be very common is COMPAS (Correctional Offender Management Profiling for Alternative Sanctions) algorithm that is used in US court systems to predict the likelihood that a defendant would become a recidivist. For prevention of bias, a richer dataset must be used for training machine learning algorithm.

### Day 11:
- A fully connected neural network is made up of a sequence of fully linked layers, each of which connects every neuron in one layer to every neuron in the other. One of the advantages of fully connected networks is that they are “structure agnostic” which means that there is no special assumptions needed to be made about the input. CNN networks, on the other hand, use the explicit assumption that the inputs are images, allowing the model architecture to encode specific features.

### Day 12 and 13:
- The Weekend

### Day 14:

- For this day we have practiced developing neural networks. For an exercise, we built a neural network predicting house prices using a simple feed-forward model.

### Day 15:

- On day 15 we have learned about different functions applied to deep learning. One of the most common functions used for hidden layers is a Rectified Linear Activation (ReLU) function, which is calculated by max(0.0, x). It is not just simple to implement, but also effective at overcoming the limitations of other functions. ReLU function is less susceptible to vanishing gradients that prevent deep models from being trained.
